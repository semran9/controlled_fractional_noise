{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c34fdf-0948-436e-8a4e-673d71bc2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchcde in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchcde) (2.1.0)\n",
      "Requirement already satisfied: torchsde>=0.2.5 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchcde) (0.2.6)\n",
      "Requirement already satisfied: torchdiffeq>=0.2.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchcde) (0.2.3)\n",
      "Requirement already satisfied: fsspec in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (3.1.2)\n",
      "Requirement already satisfied: filelock in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (3.9.0)\n",
      "Requirement already satisfied: sympy in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (2.8.4)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchdiffeq>=0.2.0->torchcde) (1.10.0)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchsde>=0.2.5->torchcde) (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchsde>=0.2.5->torchcde) (1.23.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->torchcde) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.7.0->torchcde) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Adapted from torchCDE examples\n",
    "# To-do:\n",
    "# 1. torch cdeint uses sdeint or ode int backend\n",
    "# 2. construct latent sde s.t. the deterministic part is a CDE, which can then be precomputed\n",
    "# 3. incorporate the initial + terminal values in loss specifically for cde\n",
    "# 4. precompute the sde part of the path (although then the loss n stuff is gonna get weird)\n",
    "# 5. cdeint uses sdeint backend so micht j be able to use sdeint in latent sde\n",
    "######################\n",
    "!pip install torchcde\n",
    "import math\n",
    "import torch\n",
    "import torchcde\n",
    "\n",
    "\n",
    "######################\n",
    "# A CDE model looks like\n",
    "#\n",
    "# z_t = z_0 + \\int_0^t f_\\theta(z_s) dX_s\n",
    "#\n",
    "# Where X is your data and f_\\theta is a neural network. So the first thing we need to do is define such an f_\\theta.\n",
    "# That's what this CDEFunc class does.\n",
    "# Here we've built a small single-hidden-layer neural network, whose hidden layer is of width 128.\n",
    "######################\n",
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z\n",
    "\n",
    "######################\n",
    "# Next, we need to package CDEFunc up into a model that computes the integral.\n",
    "######################\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        X = torchcde.CubicSpline(coeffs)\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "######################\n",
    "# Now we need some data.\n",
    "# Here we have a simple example which generates some spirals, some going clockwise, some going anticlockwise.\n",
    "######################\n",
    "def get_data(num_timepoints=100):\n",
    "    t = torch.linspace(0., 4 * math.pi, num_timepoints)\n",
    "\n",
    "    start = torch.rand(128) * 2 * math.pi\n",
    "    x_pos = torch.cos(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos[:64] *= -1\n",
    "    y_pos = torch.sin(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos += 0.01 * torch.randn_like(x_pos)\n",
    "    y_pos += 0.01 * torch.randn_like(y_pos)\n",
    "    ######################\n",
    "    # Easy to forget gotcha: time should be included as a channel; Neural CDEs need to be explicitly told the\n",
    "    # rate at which time passes. Here, we have a regularly sampled dataset, so appending time is pretty simple.\n",
    "    ######################\n",
    "    X = torch.stack([t.unsqueeze(0).repeat(128, 1), x_pos, y_pos], dim=2)\n",
    "    y = torch.zeros(128)\n",
    "    y[:64] = 1\n",
    "\n",
    "    perm = torch.randperm(128)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    ######################\n",
    "    # X is a tensor of observations, of shape (batch=128, sequence=100, channels=3)\n",
    "    # y is a tensor of labels, of shape (batch=128,), either 0 or 1 corresponding to anticlockwise or clockwise\n",
    "    # respectively.\n",
    "    ######################\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def main(num_epochs=30):\n",
    "    train_X, train_y = get_data()\n",
    "\n",
    "    ######################\n",
    "    # input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n",
    "    # hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "    # output_channels=1 because we're doing binary classification.\n",
    "    ######################\n",
    "    model = NeuralCDE(input_channels=3, hidden_channels=8, output_channels=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    ######################\n",
    "    # Now we turn our dataset into a continuous path. We do this here via Hermite cubic spline interpolation.\n",
    "    # The resulting `train_coeffs` is a tensor describing the path.\n",
    "    # For most problems, it's probably easiest to save this tensor and treat it as the dataset.\n",
    "    ######################\n",
    "    train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(train_X) # this is the path\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch_coeffs, batch_y = batch\n",
    "            print(batch_coeffs.shape)\n",
    "            pred_y = model(batch_coeffs).squeeze(-1)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {}   Training loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "    test_X, test_y = get_data()\n",
    "    test_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(test_X)\n",
    "    pred_y = model(test_coeffs).squeeze(-1)\n",
    "    binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "    prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "    proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "    print('Test Accuracy: {}'.format(proportion_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a927bc4f-9926-44d5-a54b-54eaff296ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "Epoch: 0   Training loss: 0.9578823447227478\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "Epoch: 1   Training loss: 0.7674970626831055\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n",
      "Epoch: 2   Training loss: 0.6765260696411133\n",
      "torch.Size([32, 99, 12])\n",
      "torch.Size([32, 99, 12])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 152\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m    150\u001b[0m batch_coeffs, batch_y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_coeffs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 152\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_coeffs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    153\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(pred_y, batch_y)\n\u001b[1;32m    154\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 81\u001b[0m, in \u001b[0;36mNeuralCDE.forward\u001b[0;34m(self, coeffs)\u001b[0m\n\u001b[1;32m     76\u001b[0m z0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial(X0)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Actually solve the CDE.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m z_T \u001b[38;5;241m=\u001b[39m \u001b[43mtorchcde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mz0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# and then apply a linear map.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m     90\u001b[0m z_T \u001b[38;5;241m=\u001b[39m z_T[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchcde/solver.py:227\u001b[0m, in \u001b[0;36mcdeint\u001b[0;34m(X, func, z0, t, adjoint, backend, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdiffeq\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    226\u001b[0m     odeint \u001b[38;5;241m=\u001b[39m torchdiffeq\u001b[38;5;241m.\u001b[39modeint_adjoint \u001b[38;5;28;01mif\u001b[39;00m adjoint \u001b[38;5;28;01melse\u001b[39;00m torchdiffeq\u001b[38;5;241m.\u001b[39modeint\n\u001b[0;32m--> 227\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchsde\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    229\u001b[0m     sdeint \u001b[38;5;241m=\u001b[39m torchsde\u001b[38;5;241m.\u001b[39msdeint_adjoint \u001b[38;5;28;01mif\u001b[39;00m adjoint \u001b[38;5;28;01melse\u001b[39;00m torchsde\u001b[38;5;241m.\u001b[39msdeint\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/adjoint.py:198\u001b[0m, in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[0m\n\u001b[1;32m    195\u001b[0m state_norm \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    196\u001b[0m handle_adjoint_norm_(adjoint_options, shapes, state_norm)\n\u001b[0;32m--> 198\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mOdeintAdjointMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                \u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madjoint_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     solution \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/adjoint.py:25\u001b[0m, in \u001b[0;36mOdeintAdjointMethod.forward\u001b[0;34m(ctx, shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, t_requires_grad, *adjoint_params)\u001b[0m\n\u001b[1;32m     22\u001b[0m ctx\u001b[38;5;241m.\u001b[39mevent_mode \u001b[38;5;241m=\u001b[39m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 25\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m         y \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/rk_common.py:265\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    255\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m _runge_kutta_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, y0, f0, t0, dt, t1, tableau\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtableau)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_error_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m accept_step \u001b[38;5;241m=\u001b[39m error_ratio \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# error_ratio.dtype == self.dtype\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m#                   Update RK State                    #\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchdiffeq/_impl/misc.py:75\u001b[0m, in \u001b[0;36m_compute_error_ratio\u001b[0;34m(error_estimate, rtol, atol, y0, y1, norm)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_error_ratio\u001b[39m(error_estimate, rtol, atol, y0, y1, norm):\n\u001b[0;32m---> 75\u001b[0m     error_tol \u001b[38;5;241m=\u001b[39m atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(y0\u001b[38;5;241m.\u001b[39mabs(), \u001b[43my1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m norm(error_estimate \u001b[38;5;241m/\u001b[39m error_tol)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0989e215-727e-43c4-be87-8751ef6ea65a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_coeffs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_coeffs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_coeffs' is not defined"
     ]
    }
   ],
   "source": [
    "test_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724d398-0be7-46f4-abc1-48552ec536ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
