{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27c34fdf-0948-436e-8a4e-673d71bc2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchcde in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchcde) (2.1.0.post100)\n",
      "Requirement already satisfied: torchdiffeq>=0.2.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchcde) (0.2.3)\n",
      "Requirement already satisfied: torchsde>=0.2.5 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchcde) (0.2.6)\n",
      "Requirement already satisfied: filelock in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torch>=1.7.0->torchcde) (2023.12.2)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchdiffeq>=0.2.0->torchcde) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchsde>=0.2.5->torchcde) (1.23.5)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from torchsde>=0.2.5->torchcde) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->torchcde) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shayaanemran/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.7.0->torchcde) (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Adapted from torchCDE examples\n",
    "# classifies a spiral\n",
    "######################\n",
    "!pip install torchcde\n",
    "import math\n",
    "import torch\n",
    "import torchcde\n",
    "\n",
    "\n",
    "######################\n",
    "# A CDE model looks like\n",
    "#\n",
    "# z_t = z_0 + \\int_0^t f_\\theta(z_s) dX_s\n",
    "#\n",
    "# Where X is your data and f_\\theta is a neural network. So the first thing we need to do is define such an f_\\theta.\n",
    "# That's what this CDEFunc class does.\n",
    "# Here we've built a small single-hidden-layer neural network, whose hidden layer is of width 128.\n",
    "######################\n",
    "class CDEFunc(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        ######################\n",
    "        # input_channels is the number of input channels in the data X. (Determined by the data.)\n",
    "        # hidden_channels is the number of channels for z_t. (Determined by you!)\n",
    "        ######################\n",
    "        super(CDEFunc, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    ######################\n",
    "    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n",
    "    # different times, which would be unusual. But it's there if you need it!\n",
    "    ######################\n",
    "    def forward(self, t, z):\n",
    "        # z has shape (batch, hidden_channels)\n",
    "        z = self.linear1(z)\n",
    "        z = z.relu()\n",
    "        z = self.linear2(z)\n",
    "        ######################\n",
    "        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n",
    "        ######################\n",
    "        z = z.tanh()\n",
    "        ######################\n",
    "        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n",
    "        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n",
    "        ######################\n",
    "        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n",
    "        return z\n",
    "\n",
    "######################\n",
    "# Next, we need to package CDEFunc up into a model that computes the integral.\n",
    "######################\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"cubic\"):\n",
    "        super(NeuralCDE, self).__init__()\n",
    "\n",
    "        self.func = CDEFunc(input_channels, hidden_channels)\n",
    "        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        X = torchcde.CubicSpline(coeffs)\n",
    "        ######################\n",
    "        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n",
    "        ######################\n",
    "        X0 = X.evaluate(X.interval[0])\n",
    "        z0 = self.initial(X0)\n",
    "\n",
    "        ######################\n",
    "        # Actually solve the CDE.\n",
    "        ######################\n",
    "        z_T = torchcde.cdeint(X=X,\n",
    "                              z0=z0,\n",
    "                              func=self.func,\n",
    "                              t=X.interval)\n",
    "\n",
    "        ######################\n",
    "        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n",
    "        # and then apply a linear map.\n",
    "        ######################\n",
    "        z_T = z_T[:, 1]\n",
    "        pred_y = self.readout(z_T)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "######################\n",
    "# Now we need some data.\n",
    "# Here we have a simple example which generates some spirals, some going clockwise, some going anticlockwise.\n",
    "######################\n",
    "def get_data(num_timepoints=100):\n",
    "    t = torch.linspace(0., 4 * math.pi, num_timepoints)\n",
    "\n",
    "    start = torch.rand(128) * 2 * math.pi\n",
    "    x_pos = torch.cos(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos[:64] *= -1\n",
    "    y_pos = torch.sin(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n",
    "    x_pos += 0.01 * torch.randn_like(x_pos)\n",
    "    y_pos += 0.01 * torch.randn_like(y_pos)\n",
    "    ######################\n",
    "    # Easy to forget gotcha: time should be included as a channel; Neural CDEs need to be explicitly told the\n",
    "    # rate at which time passes. Here, we have a regularly sampled dataset, so appending time is pretty simple.\n",
    "    ######################\n",
    "    X = torch.stack([t.unsqueeze(0).repeat(128, 1), x_pos, y_pos], dim=2)\n",
    "    y = torch.zeros(128)\n",
    "    y[:64] = 1\n",
    "\n",
    "    perm = torch.randperm(128)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    ######################\n",
    "    # X is a tensor of observations, of shape (batch=128, sequence=100, channels=3)\n",
    "    # y is a tensor of labels, of shape (batch=128,), either 0 or 1 corresponding to anticlockwise or clockwise\n",
    "    # respectively.\n",
    "    ######################\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def main(num_epochs=30):\n",
    "    train_X, train_y = get_data()\n",
    "\n",
    "    ######################\n",
    "    # input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n",
    "    # hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "    # output_channels=1 because we're doing binary classification.\n",
    "    ######################\n",
    "    model = NeuralCDE(input_channels=3, hidden_channels=8, output_channels=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    ######################\n",
    "    # Now we turn our dataset into a continuous path. We do this here via Hermite cubic spline interpolation.\n",
    "    # The resulting `train_coeffs` is a tensor describing the path.\n",
    "    # For most problems, it's probably easiest to save this tensor and treat it as the dataset.\n",
    "    ######################\n",
    "    train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(train_X) # this is the path\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch_coeffs, batch_y = batch\n",
    "            #print(batch_coeffs.shape)\n",
    "            pred_y = model(batch_coeffs).squeeze(-1)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('Epoch: {}   Training loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "    test_X, test_y = get_data()\n",
    "    test_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(test_X)\n",
    "    pred_y = model(test_coeffs).squeeze(-1)\n",
    "    binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "    prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "    proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "    print('Test Accuracy: {}'.format(proportion_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a927bc4f-9926-44d5-a54b-54eaff296ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Training loss: 0.705207884311676\n",
      "Epoch: 1   Training loss: 0.7207801342010498\n",
      "Epoch: 2   Training loss: 0.5896622538566589\n",
      "Epoch: 3   Training loss: 0.5244104266166687\n",
      "Epoch: 4   Training loss: 0.42858946323394775\n",
      "Epoch: 5   Training loss: 0.2616773545742035\n",
      "Epoch: 6   Training loss: 0.13357147574424744\n",
      "Epoch: 7   Training loss: 0.04926823452115059\n",
      "Epoch: 8   Training loss: 0.014703855849802494\n",
      "Epoch: 9   Training loss: 0.006092860829085112\n",
      "Epoch: 10   Training loss: 0.003314698813483119\n",
      "Epoch: 11   Training loss: 0.0021478570997714996\n",
      "Epoch: 12   Training loss: 0.0015572032425552607\n",
      "Epoch: 13   Training loss: 0.0012099526356905699\n",
      "Epoch: 14   Training loss: 0.0009844547603279352\n",
      "Epoch: 15   Training loss: 0.0008325467933900654\n",
      "Epoch: 16   Training loss: 0.0007060338975861669\n",
      "Epoch: 17   Training loss: 0.000603444583248347\n",
      "Epoch: 18   Training loss: 0.0005135740502737463\n",
      "Epoch: 19   Training loss: 0.0004324360052123666\n",
      "Epoch: 20   Training loss: 0.000358386809239164\n",
      "Epoch: 21   Training loss: 0.0003000517899636179\n",
      "Epoch: 22   Training loss: 0.00024816393852233887\n",
      "Epoch: 23   Training loss: 0.0002049919858109206\n",
      "Epoch: 24   Training loss: 0.0001700513530522585\n",
      "Epoch: 25   Training loss: 0.00014158306294120848\n",
      "Epoch: 26   Training loss: 0.00012174115545349196\n",
      "Epoch: 27   Training loss: 0.00010666145681170747\n",
      "Epoch: 28   Training loss: 9.482895256951451e-05\n",
      "Epoch: 29   Training loss: 8.573728700866923e-05\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989e215-727e-43c4-be87-8751ef6ea65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724d398-0be7-46f4-abc1-48552ec536ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
